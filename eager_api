from datetime import datetime
import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import decomposition
from sklearn import preprocessing
import os
# Set Eager API
tf.enable_eager_execution()
tfe = tf.contrib.eager
# record initial time
tic = datetime.now()
# initialize the number of cells in the hidden layers
cell = [110, 30]


# initialize the parameters
class Para:
    pca_component = 90
    input_cells = 178
    drop_rate = 0.5
    learning_rate = 0.15
    iteration = 201
    n_hidden_1 = cell[0]
    n_hidden_2 = cell[1]
    seed_number = 1
    path_results = 'D:/QuantCN/nn_result/nn_together/等权组合/Oct_Week2/Sat/test14/' + str(n_hidden_1) + '-' \
                   + str(n_hidden_2) + '-seed' + str(seed_number) + '/'


para = Para()
# initialize random seeds
tf.set_random_seed(para.seed_number)
np.random.seed(para.seed_number)

# make a directory to restore the results
os.mkdir(para.path_results)
# info.txt records the information of the model
info_file = open(para.path_results + 'info.txt', 'a')
info_file.write('input =' + str(para.input_cells) + '\n' + 'pca_select = ' + str(para.pca_component) + '\n' +
                'number of cells in layer1 = ' + str(para.n_hidden_1) + '\n' + 'number of cells in layer2 = ' +
                str(para.n_hidden_2) + '\n' + 'drop_rate = ' + str(para.drop_rate) + '\n' + 'learning_rate = ' +
                str(para.learning_rate) + '\n' + 'iteration = ' + str(para.iteration) + '\n')
info_file.close()

# ## Prepare dataset
filename1 = 'D:/QuantCN/nn_result/nn_together/等权组合/Oct_Week2/Mon/factors/factors_all.csv'

df1 = pd.read_csv(filename1, encoding='gb18030', low_memory=False)

labels_df = df1.loc[:, ['OptionCode', 'EndDate', 'rtn', 'rtn_roll_-1', 'rtn_co', 'rtn_olc']]
values_df = df1.iloc[:, 19:]
df = pd.concat([labels_df, values_df], axis=1)
df['EndDate'] = df.loc[:, 'EndDate'].apply(lambda x: pd.Timestamp(x))
df = df.sort_values(by=['EndDate'], ascending=True)
df = df.reset_index(drop=True)
df_row, df_col = df.shape

factors_columns = df.iloc[:, 6:].columns.to_list()

option = labels_df.OptionCode.unique()
num_option = len(option)
End_Date = df.EndDate.unique()
num_date = len(End_Date)

###############################################################################

# Define the neural network. To use eager API and tf.layers API together,
# we must instantiate a tfe.Network class as follow:


class NeuralNet(tfe.Network):
    def __init__(self):
        # Define each layer
        super(NeuralNet, self).__init__()
        # Hidden fully connected layer with n_hidden_1 neurons
        self.layer1 = self.track_layer(
            tf.layers.Dense(para.n_hidden_1, activation=tf.nn.tanh))
        # Hidden fully connected layer with n_hidden_1 neurons
        self.layer2 = self.track_layer(
            tf.layers.Dense(para.n_hidden_2, activation=tf.nn.tanh))
        # Output fully connected layer with a neuron for each class
        self.out_layer = self.track_layer(tf.layers.Dense(1))

    def call(self, x):
        x = self.layer1(x)
        x = self.layer2(x)
        return self.out_layer(x)


neural_net = NeuralNet()

# MSE loss function


def loss_fn(inference_fn, inputs, ys):
    # Using Mean Square Errors
    return 0.5 * tf.losses.mean_squared_error(inference_fn(inputs), ys)


# Predict test sets
def test_fn(inference_fn, inputs):
    prediction = inference_fn(inputs)
    return prediction


# SGD Optimizer
optimizer = tf.train.AdamOptimizer(learning_rate=para.learning_rate)
# Compute gradients
grad = tfe.implicit_gradients(loss_fn)

pred_df = pd.DataFrame(columns=['OptionCode', 'EndDate', 'rtn', 'rtn_roll_-1', 'rtn_co', 'rtn_olc'] + list(
    range(para.pca_component)) + ['pred_rtn'])

for i in range(251, num_date):
    print(End_Date[i])
    error_file = open(para.path_results + 'error.txt', 'a')
    error_file.write(str(End_Date[i]) + '\n')
    df2 = df.loc[np.isin(df.loc[:, 'EndDate'].values, End_Date[i - 251: i + 1])]
    df2.reset_index(drop=True, inplace=True)
    x_factors = df2.iloc[:, 6:].values
    x_label = df2.iloc[:, :6]

    scaler = preprocessing.StandardScaler().fit(x_factors)
    x_factors = scaler.transform(x_factors)

    pca = decomposition.PCA(n_components=para.pca_component)
    pca.fit(x_factors)
    x_factors = pca.transform(x_factors)

    x_factors_df = pd.DataFrame(x_factors, columns=list(range(para.pca_component)))
    df3 = pd.concat([x_label, x_factors_df], axis=1)

    df4 = df3.loc[np.isin(df3.loc[:, 'EndDate'].values, End_Date[i - 251: i - 1])]
    x_data = df4.iloc[:, 6:].values
    x_data_pred_df = df3.loc[np.isin(df3.loc[:, 'EndDate'].values, End_Date[i])]

    y_data = df4.loc[:, 'rtn_roll_-1'].values.reshape(df4.iloc[:, 0].size, 1)
    y_data = y_data * 100

    for k in range(para.iteration):

        # Update the variables following gradients info
        optimizer.apply_gradients(grad(neural_net, x_data, y_data))

        if k % 50 == 0 or k == 1:
            error_file.write(str(loss_fn(neural_net, x_data, y_data)) + '\n')

    error_file.close()

    pred_inputs = x_data_pred_df.iloc[:, 6:].values
    pred_rtn = test_fn(neural_net, pred_inputs)

    num_col = x_data_pred_df.shape[1]
    x_data_pred_df.insert(loc=num_col, column='pred_rtn', value=pred_rtn)
    pred_df = pd.concat([pred_df, x_data_pred_df], axis=0, ignore_index=True)

pred_df_all = pd.DataFrame()
os.mkdir(para.path_results + 'pred/')
os.mkdir(para.path_results + 'graphs/')
for j in range(num_option):
    code = option[j]
    print(code)
    sub_df = pred_df.loc[pred_df.loc[:, 'OptionCode'] == code]
    sub_df_size = sub_df.iloc[:, 0].size
    if sub_df_size > 0:
        sub_df.reset_index(drop=True, inplace=True)
        pred_rtn = sub_df.loc[:, 'pred_rtn'].values
        pred_rtn = [x[0].numpy() for x in pred_rtn]
        tmp_indicator = np.sign(np.array(pred_rtn))
        indicator = np.roll(tmp_indicator, 1)
        indicator[0] = 0

        actual_rtn = sub_df.loc[:, 'rtn'].values * indicator

        net_value = (actual_rtn + 1).cumprod()

        tmp_max = np.maximum.accumulate(net_value)
        draw_down = net_value / tmp_max - 1
        daily_indicator = pd.DataFrame({'indicator': indicator, 'actual_rtn': actual_rtn, 'net_value': net_value,
             'draw_down': draw_down})

        sub_df = pd.concat([sub_df, daily_indicator], axis=1)
        sub_df.to_excel(para.path_results + 'pred/' + str(code) + '.xlsx', encoding='gb18030', index=False)
        pred_df_all = pd.concat([pred_df_all, sub_df], axis=0, ignore_index=True)
        # plot
        x = list(range(sub_df_size))
        y = net_value
        z = draw_down

        fig = plt.figure()
        ax1 = fig.add_subplot(111)
        l1, = ax1.plot(x, y, 'b', label='net value')
        ax1.set_ylabel('Net Value')
        ax1.set_yticks([0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2])
        ax1.set_title(str(code))

        ax2 = ax1.twinx()  # this is the important function
        l2, = ax2.plot(x, z, 'r', label='draw down')
        ax2.fill_between(x, z, where=(z < 0), facecolor='red')
        ax2.set_ylabel('Draw Down')
        ax2.set_yticks([-1, -0.9, -0.8, -0.7, -0.6, -0.5, -0.4, -0.3, -0.2, -0.1, 0])
        Date = sub_df.EndDate.unique()
        num_Date = len(Date)
        Date = pd.DataFrame(Date)
        Date = Date.loc[:, 0].apply(lambda x: str(x)[:-9])
        plt.xticks(ticks=list(np.linspace(0, num_Date, 5, endpoint=False, dtype=int)), labels=list(
            Date.loc[list(np.linspace(0, num_Date, 5, endpoint=False, dtype=int))].values))
        plt.xticks(rotation=90)
        plt.legend(handles=[l1, l2], labels=['net value', 'draw down'], loc='lower left')
        plt.savefig(para.path_results + 'graphs/' + str(int(code)) + '.png', dpi=120)
        plt.close(fig)

pred_df_all.to_excel(para.path_results + 'pred_all.xlsx', encoding='gb18030', index=False)

Date1 = pred_df_all.EndDate.unique()
num1 = len(Date1)
Date = pd.DataFrame(Date1)
Date = Date.loc[:, 0].apply(lambda x: str(x)[:-9])
rtn = np.zeros(num1)

for i in range(num1):
    sub_df = pred_df_all.loc[pred_df_all.loc[:, 'EndDate'] == Date1[i]]
    rtn[i] = np.mean(sub_df.loc[:, 'actual_rtn'].values)

net_value_all = (1 + rtn).cumprod()

tmp_max_all = np.maximum.accumulate(net_value_all)
draw_down_all = net_value_all / tmp_max_all - 1

data = {'date': Date, 'rtn': list(rtn), 'net_value': list(net_value_all), 'draw_down': list(draw_down_all)}
port_indicator = pd.DataFrame(data)

port_indicator.to_excel(para.path_results + 'port_indicator.xlsx', encoding='gb18030', index=False)

x = range(1, num1 + 1)
fig2 = plt.figure()
ax1 = fig2.add_subplot(111)
l1, = ax1.plot(x, net_value_all, 'b', label='net value')
ax1.set_ylabel('Net Value')
ax1.set_yticks([0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2])
ax1.set_title('portfolio indicators')

ax2 = ax1.twinx()  # this is the important function
l2, = ax2.plot(x, draw_down_all, 'r', label='draw down')
ax2.fill_between(x, draw_down_all, where=(draw_down_all < 0), facecolor='red')

ax2.set_ylabel('Draw Down')
ax2.set_yticks([-0.5, -0.4, -0.3, -0.2, -0.1, 0])
ax2.set_xlabel('End Date')

plt.xticks(ticks=list(np.linspace(0, num1, 5, endpoint=False, dtype=int)), labels=list(
    Date.loc[list(np.linspace(0, num1, 5, endpoint=False, dtype=int))].values))
plt.legend(handles=[l1, l2], labels=['net value', 'draw down'], loc='lower left')
plt.savefig(para.path_results + 'port_indicator.png', dpi=120)
plt.close(fig2)
toc = datetime.now()
print(toc)
print(toc - tic)
